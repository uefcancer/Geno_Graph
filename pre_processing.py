import os
import subprocess
import allel
import pandas as pd
from glob import glob
from tqdm import tqdm
from itertools import product


def genotype_preprocessing(vcf_path, save_df_path, log_file_path, maf=0.01, hwe=1e-5, r2=0.8):
    print('[INFO: Starting] PLINK genotype pre-processing pipeline ....')

    commands = [
        ["plink", "--vcf", vcf_path, "--allow-extra-chr", "--geno", "0.1", "--maf", str(maf), "--hwe", str(hwe), "--indep-pairwise", "50", "5", str(r2), "--make-bed", "--out", "filtered_data"],
        ["plink", "--bfile", "filtered_data", "--allow-extra-chr", "--extract", "filtered_data.prune.in", "--make-bed", "--out", "final_data"]
    ]

    with open(log_file_path, 'a') as log_file:
        # Execute each PLINK command
        for command in commands:
            subprocess.run(command, stdout=log_file, stderr=log_file, text=True)

    print('[INFO: Ending] PLINK genotype pre-processing pipeline ....')

    prune_in_file = "filtered_data.prune.in"

    # Read the file and extract the contents into a list
    with open(prune_in_file, "r") as file:
        SNP_ids = file.read().splitlines()

    # Load VCF file from biobank dataset
    print('[INFO:] Loading BioBank VCF data:', vcf_path)
    callset = allel.read_vcf(vcf_path)
    print(callset.keys())
    print('[INFO:] Loaded VCF file')

    samples = callset['samples']
    print('Number of Samples:', len(samples))  # Number of samples
    print('Number of Variants/SNPs Found:', len(callset['variants/ID']))  # Number of variants (SNPs) found in BioBank

    # Create a set of SNP IDs for efficient lookup
    snp_ids_set = set(SNP_ids)
    variant_ids = callset['variants/ID']

    # Create an empty list to store the genotype arrays
    genotype_arrays = []

    SNPs = []
    # Iterate over the variant IDs and check if they are present in SNP_ids
    for i, variant_id in enumerate(variant_ids):
        if variant_id in snp_ids_set:
            SNPs.append(variant_id)
            # Variant is present in SNP_ids, extract the genotype array
            genotype_array = callset['calldata/GT'][i]
            genotype_arrays.append(genotype_array)

    # Convert the list of genotype arrays into a single GenotypeArray object
    genotype_array_all = allel.GenotypeArray(genotype_arrays)
    gn_matrix = genotype_array_all.to_n_alt()

    print(gn_matrix.shape)
    gn_matrix = gn_matrix.T
    print(gn_matrix.shape)  # (#samples, #SNPs)

    # Convert genotype matrix to pandas DataFrame for further analysis
    chr_df = pd.DataFrame(gn_matrix, columns=SNPs, index=samples) 
    chr_df.to_csv(save_df_path, header=True, index=True)

    # Delete intermediate files generated by PLINK
    intermediate_files = [ "filtered_data.bim", "filtered_data.bed", "filtered_data.fam", 
                          "filtered_data.log", "filtered_data.nosex", 
                          "filtered_data.prune.out", "final_data.bed", "final_data.bim", "final_data.fam", "final_data.log",
                          "final_data.nosex"] 

    for file_name in intermediate_files:
        file_path = os.path.join(os.getcwd(), file_name)
        if os.path.exists(file_path):
            os.remove(file_path)

    print('Intermediate files deleted.')

def main(is_imputed=False):
    # Create directories if they don't exist
    os.makedirs('data/biobank/genotype/processed_imputed', exist_ok=True)
    os.makedirs('data/biobank/genotype/processed_raw', exist_ok=True)

    # Working with raw genotype data
    if not is_imputed:
        raw_vcf_files = glob("data/biobank/genotype/original/BCA_output_raw/*.vcf.gz")

        for vcf_path in tqdm(raw_vcf_files):
            f_id = os.path.split(vcf_path)[-1].split('.')[0]
            save_dir = os.path.join("data/biobank/genotype/processed_raw", combination_dir)
            os.makedirs(save_dir, exist_ok=True)
            save_df_path = os.path.join(save_dir, f_id + '.csv')
            log_file_path = os.path.join(save_dir, f_id + '.txt')
            genotype_preprocessing(vcf_path=vcf_path, save_df_path=save_df_path, log_file_path=log_file_path,maf=maf, hwe=hwe, r2=r2)

    # Working with imputed genotype data
    if is_imputed:
        vcf_files = glob("data/biobank/genotype/original/BCA_output_imputed/*.vcf.gz")

        for vcf_path in tqdm(vcf_files):
            f_id = os.path.split(vcf_path)[-1].split('.')[0]
            save_dir = os.path.join("data/biobank/genotype/processed_imputed", combination_dir)
            os.makedirs(save_dir, exist_ok=True)

            save_df_path = os.path.join(save_dir, f_id + '.csv')
            log_file_path = os.path.join(save_dir, f_id + '.txt')
            genotype_preprocessing(vcf_path=vcf_path, save_df_path=save_df_path, log_file_path=log_file_path,maf=maf, hwe=hwe, r2=r2)

# Initialize counters for total combinations and completed combinations
total_combinations = 0
completed_combinations = 0

maf_range = [0.01, 0.02, 0.05, 0.1]
hwe_range = [1e-07, 1e-06, 1e-05, 1e-04]
r2 = [0.5, 0.6, 0.7, 0.8]

#maf_range = [0.01]
#hwe_range = [1e-07]
#r2 = [0.5]
combinations = list(product(maf_range, hwe_range, r2))

# Calculate the total number of combinations
total_combinations = len(combinations)
print(f"Total combinations: {total_combinations}")

# Loop through the combinations and process them
for combination in tqdm(combinations):
    maf, hwe, r2 = combination
    combination_dir = f"maf_{maf}_hwe_{hwe}_r2_{r2}"
    # Skip the combination if the combination_dir already exists
    if os.path.exists(os.path.join("data/biobank/genotype/processed_imputed", combination_dir)):
        continue
    
    #main(is_imputed=False)
    main(is_imputed=True)
    completed_combinations += 1

    # Print the progress
    print(f"Completed combinations: {completed_combinations}/{total_combinations}")

